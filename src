##rag_basic.py

from sentence_transformers import SentenceTransformer
import numpy as np

#Load the embedding model
embedder = SentenceTransformer("all-MiniLM-L6-v2")

#Load Document
with open ("sample_doc.txt", "r") as f:
  document = f.read()

#Create embedding
doc_embedding = embedder.encode(document)

def retrieve_context(query, doc_embedding, document):
  query_embedding = embedder.encode(query)

  similarity = np.dot(query_embedding, doc_embedding) / (
    np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
  )

  return document if similarity > 0.2 else ""

import requests

def ask_llm(context, question):
  prompt = f"
Use the following context to answer the question.

Context:
(context)

Question:
{question}
"""

  response = requests.post(
    "http://localhost:11434/api/generate",
    json={
      "model": "phi4:latest",
      "prompt": prompt,
      "stream": False
    }
)

return response.json()["response"]

if __name__ == "__main__":
  main()
  question = "What is Retrieval-Augmented Genertion?"

  context = retreive_context(question, doc_embedding, document)
  answer = ask_llm(context, question)

  print("Answer:\n", answer)

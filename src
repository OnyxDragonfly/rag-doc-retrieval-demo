##rag_basic.py

from sentence_transformers import SentenceTransformer
import numpy as np

#Load the embedding model
embedder = SentenceTransformer("phi4:latest")

#Load Document
with open ("sample_doc.txt", "r") as f:
  document = f.read()

#Create embedding
doc_embedding = embedder.encode(document)

def retrieve_context(query, doc_embedding, document):
  query_embedding = embedder.encode(query)

similarity = np.dot(query_embedding, doc_embedding) / (
  np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
)

return dicument if similarity > 0.2 else ""

import requests

def ask_llm(context, queston):
  prompt = f""
Use the following context to answer the question.

Context:
(Context)

Question:
{question}
"""

  response = requests.post(
    "http://localhost:11434/api/generate",
    json={
      "model": "phi4:latest"
      "prompt": promopt,
      "stream": False
    }
)

return response.json()["response"]

if__name__=="__main__":
  question = "What is Retrieval-Augmented Genertion?"

  context = retreive_context(question, doc_embedding, document)
  answer = ask_llm(context, question)

  print("Answer:\n", answer)
